# Eve-ng lab from topology file
 
Uses the [evengsdk topology builder](https://ttafsir.github.io/evengsdk/topology_builder/) tool to deploy a lab from a topology file with the device startup config generated by jinja templates.

**nodes:** A list of the devices to be created and their attributes, think can add any of the options that the API supports such as *ethernet*, *cpu*, etc

```yaml
- name: Device name
    template: The device type, can see the different options with the cmd "eve-ng --host 'x.y.z.z' --username me --password 'pass' list-node-templates"
    image: Template images, for example to see the vios images (are in options >> image >> list dictionary) "eve-ng --host 'x.y.z.z' --username me --password 'pass' show-template vios"
    node_type: Majority of time will be qmeu, although can also have ios dynamips (Cisco IOS emulation) and iol (IOS on Linux also known as IOU)
    left: Percentage to merge from the left
    top: Percentage to merge from the top
    configuration: Specify either a static config file or a template and variables (vars)
      file: The configuration file name
      template: Jinja template name, by default looks for it in /templates folder unless specified otherwise at runtime with --template-dir
      vars: Dictionary of variables used when the template file is rendered
```

A few commands that are useful to gather the *template* (device type) and *image* (os version) names:

- **eve-ng --host** *"10.30.10.105"* **--username** *admin* **--password** *'pa$$w0rd'* **list-node-templates**
- **eve-ng --host** *"10.30.10.105"* **--username** *admin* **--password** *'pa$$w0rd'* **show-template** *<template_name>*

**links:** A list of dictionaries that contain connections between devices (*node*) and connections between devices and clouds/pnets (*network*)

```yaml
network:
    - {"src": "node_a", "src_label": "intf_a", "dst": "inet"}
node:
    - {"src": "node_a", "src_label": "intf_a", "dst": "node_b", "dst_label": "intf_b"}
```

A good starting point is to list all the existing labs on EVE-NG and gather their paths as this will be needed in future commands.

```bash
❯ eve-ng --host "10.30.10.105" --username admin --password 'pa$$w0rd' lab list
                                                                               Labs
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┓
┃                         Name ┃ Path                                            ┃ Description                                     ┃ Author                ┃ Lock ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━┩
│                         test │ /test.unl                                       │                                                 │                       │ 0    │
│   fos multi-site  pre-checks │ /fos_labs/fos multi-site  pre-checks.unl        │                                                 │                       │ 0    │
│  Pre-check - Access Switches │ /precheck_labs/Pre-check - Access Switches.unl  │                                                 │                       │ 0    │
│                   pre_check1 │ /precheck_labs/pre_check1.unl                   │                                                 │                       │ 0    │
│                 ospf netconf │ /scratch/ospf netconf.unl                       │ for testing OSPF netconf between CSRs           │                       │ 0    │
│                        test1 │ /scratch/test1.unl                              │                                                 │                       │ 0    │
└──────────────────────────────┴─────────────────────────────────────────────────┴─────────────────────────────────────────────────┴───────────────────────┴──────┘
```

To get a feel for the parameters to be set in the topology file it is useful to look at any existing labs, I found the API was best for this as the SDK dumbed down the info too much. These commands got the *nodes* and *networks* in my *test1* lab which I than used to build my topology file.

```bash
curl -s -b /tmp/cookie -c /tmp/cookie -X POST -d '{"username":"admin","password":"pa$$w0rd"}' http://10.30.10.105/api/auth/login | ct
curl -s -c /tmp/cookie -b /tmp/cookie -X GET -H 'Content-type: application/json' http://10.30.10.105/api/labs/scratch/test1.unl/networks | python -m json.tool | ct
curl -s -c /tmp/cookie -b /tmp/cookie -X GET -H 'Content-type: application/json' http://10.30.10.105/api/labs/scratch/test1.unl/nodes | python -m json.tool | ct
```

The *eveng_lab_topo.yml* file defines the topology to be deployed, can use *--template-dir* to set the jinja templates location (defaults to */templates*)

```bash
❯ eve-ng --host "10.30.10.105" --username admin --password 'pa$$w0rd' lab create-from-topology -t eveng_lab_topo.yml
[11:57:25] Lab created: /scratch/cisco_topo.unl                                                                                                     commands.py:452
[11:57:28] node isp01 completed                                                                                                                     commands.py:202
           network mgmt completed. ID: 1                                                                                                            commands.py:226
           network inet completed. ID: 2                                                                                                            commands.py:226
[11:57:29] link isp01:Gi0/0 -> inet completed                                                                                                       commands.py:146
           link isp02:Gi0/0 -> inet completed                                                                                                       commands.py:146
           link isp01:Gi0/7 -> mgmt completed                                                                                                       commands.py:146
           link isp02:Gi0/7 -> mgmt completed                                                                                                       commands.py:146
           link csr01:Gi8 -> mgmt completed                                                                                                         commands.py:146
           link csr02:Gi8 -> mgmt completed                                                                                                         commands.py:146
[11:57:30] link xnet01:Gi0/7 -> mgmt completed                                                                                                      commands.py:146
           link asa01:Mgmt0/0 -> mgmt completed                                                                                                     commands.py:146
           link core01:Gi0/7 -> mgmt completed                                                                                                      commands.py:146
           link access01:Gi0/7 -> mgmt completed                                                                                                    commands.py:146
[11:57:31] link isp01:Gi0/1 <-> csr01:Gi1 completed                                                                                                 commands.py:166
[11:57:32] link isp02:Gi0/1 <-> csr02:Gi1 completed                                                                                                 commands.py:166
[11:57:33] link csr01:Gi2 <-> csr02:Gi2 completed                                                                                                   commands.py:166
[11:57:34] link csr01:Gi3 <-> xnet01:Gi0/0 completed                                                                                                commands.py:166
[11:57:35] link csr02:Gi3 <-> xnet01:Gi0/1 completed                                                                                                commands.py:166
           link xnet01:Gi0/3 <-> asa01:Gi0/0 completed                                                                                              commands.py:166
[11:57:36] link asa01:Gi0/1 <-> core01:Gi0/0 completed                                                                                              commands.py:166
[11:57:37] link core01:Gi0/1 <-> access01:Gi0/0 completed                                                                                           commands.py:166
           link access01:Gi0/1 <-> workstation01:e0 completed                                                                                       commands.py:166
```

This created the following topology:

<img width="1000" alt="Image" src="https://github.com/user-attachments/assets/6ee52f3c-e804-4d97-89c5-d6f9e46187ca" />

You need to manually enable the startup-configs for the nodes, can do for all under *more actions -> Set nodes startup-cfg to exported*. All nodes in a lab can be started and stopped individual (with *node-id*) or all at once. The full lab path needs specifying for these and any of other lab verification commands.

```bash
eve-ng --host "10.30.10.105" --username admin --password 'pa$$w0rd' node start -n <node_id>  --path /scratch/cisco_topo.unl
eve-ng --host "10.30.10.105" --username admin --password 'pa$$w0rd' lab start --path /scratch/cisco_topo.unl
eve-ng --host "10.30.10.105" --username admin --password 'pa$$w0rd' node stop -n <node_id>  --path /scratch/cisco_topo.unl
eve-ng --host "10.30.10.105" --username admin --password 'pa$$w0rd' lab stop --path /scratch/cisco_topo.unl
```

```bash
❯ eve-ng --host "10.30.10.105" --username admin --password 'pa$$w0rd' node list  --path /scratch/cisco_topo.unl
                                                       Nodes @ /scratch/cisco_topo.unl
                                                     Nodes @ /scratch/cisco_topo.unl
┏━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━┳━━━━━┓
┃ Id ┃ Name          ┃ Url                         ┃ Image                            ┃ Template   ┃ Status      ┃ Console ┃ Ram  ┃ Cpu ┃
┡━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━╇━━━━━┩
│  1 │ isp01         │ telnet://10.40.10.120:32897 │ vios-adventerprisek9-m-15.6.2T   │ vios       │ started 🟠  │ telnet  │ 1024 │ 1   │
│  2 │ isp02         │ telnet://10.40.10.120:32898 │ vios-adventerprisek9-m-15.6.2T   │ vios       │ started 🟠  │ telnet  │ 1024 │ 1   │
│  3 │ csr02         │ telnet://10.40.10.120:32899 │ csr1000vng-universalk9.17.03.04a │ csr1000vng │ building 🔴 │ telnet  │ 4096 │ 1   │
│  4 │ core01        │ telnet://10.40.10.120:32900 │ vios-adventerprisek9-m-15.6.2T   │ vios       │ started 🟠  │ telnet  │ 1024 │ 1   │
│  5 │ asa01         │ telnet://10.40.10.120:32901 │ asav-992                         │ asav       │ started 🟠  │ telnet  │ 2048 │ 1   │
│  6 │ csr01         │ telnet://10.40.10.120:32902 │ csr1000vng-universalk9.17.03.04a │ csr1000vng │ building 🔴 │ telnet  │ 4096 │ 1   │
│  7 │ xnet01        │ telnet://10.40.10.120:32903 │ vios-adventerprisek9-m-15.6.2T   │ vios       │ started 🟠  │ telnet  │ 1024 │ 1   │
│  8 │ access01      │ telnet://10.40.10.120:32904 │ vios-adventerprisek9-m-15.6.2T   │ vios       │ started 🟠  │ telnet  │ 1024 │ 1   │
│  9 │ workstation01 │ telnet://10.40.10.120:32905 │ win-7                            │ win        │ started 🟠  │ telnet  │ 4096 │ 1   │
└────┴───────────────┴─────────────────────────────┴──────────────────────────────────┴────────────┴─────────────┴─────────┴──────┴─────┘

❯ eve-ng --host "10.30.10.105" --username admin --password 'pa$$w0rd' lab topology  --path /scratch/cisco_topo.unl
┏━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Type     ┃ Source ┃ Source Type ┃ Source Label ┃ Destination ┃ Destination Type ┃ Destination Label ┃
┡━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ ethernet │ node1  │ node        │ Gi0/0        │  network2   │ network          │                   │
│ ethernet │ node1  │ node        │ Gi0/7        │  network1   │ network          │                   │
│ ethernet │ node2  │ node        │ Gi0/0        │  network2   │ network          │                   │
│ ethernet │ node2  │ node        │ Gi0/7        │  network1   │ network          │                   │
│ ethernet │ node3  │ node        │ Gi1          │    node2    │ node             │ Gi0/1             │
│ ethernet │ node3  │ node        │ Gi8          │  network1   │ network          │                   │
│ ethernet │ node4  │ node        │ Gi0/7        │  network1   │ network          │                   │
│ ethernet │ node5  │ node        │ Mgmt0/0      │  network1   │ network          │                   │
│ ethernet │ node5  │ node        │ Gi0/1        │    node4    │ node             │ Gi0/0             │
│ ethernet │ node6  │ node        │ Gi1          │    node1    │ node             │ Gi0/1             │
│ ethernet │ node6  │ node        │ Gi2          │    node3    │ node             │ Gi2               │
│ ethernet │ node6  │ node        │ Gi8          │  network1   │ network          │                   │
│ ethernet │ node7  │ node        │ Gi0/0        │    node6    │ node             │ Gi3               │
│ ethernet │ node7  │ node        │ Gi0/1        │    node3    │ node             │ Gi3               │
│ ethernet │ node7  │ node        │ Gi0/3        │    node5    │ node             │ Gi0/0             │
│ ethernet │ node7  │ node        │ Gi0/7        │  network1   │ network          │                   │
│ ethernet │ node8  │ node        │ Gi0/0        │    node4    │ node             │ Gi0/1             │
│ ethernet │ node8  │ node        │ Gi0/7        │  network1   │ network          │                   │
│ ethernet │ node9  │ node        │ e0           │    node8    │ node             │ Gi0/1             │
└──────────┴────────┴─────────────┴──────────────┴─────────────┴──────────────────┴───────────────────┘

❯ eve-ng --host "10.30.10.105" --username admin --password 'pa$$w0rd' node read -n 1  --path /scratch/cisco_topo.unl
{
  "console": "telnet",
  "config": "1",
  "delay": 0,
  "left": 220,
  "icon": "Router2.png",
  "image": "vios-adventerprisek9-m-15.6.2T",
  "name": "isp01",
  "status": 3,
  "template": "vios",
  "type": "qemu",
  "top": 250,
  "url": "telnet://10.40.10.120:32897",
  "cpulimit": 1,
  "cpu": 1,
  "ethernet": 8,
  "ram": 1024,
  "uuid": "2517a2c0-2863-4a46-a606-a19f06e53af6",
  "qemu_options": "-machine type=pc,accel=kvm -serial mon:stdio -nographic -no-user-config -nodefaults -rtc base=utc -cpu host",
  "qemu_version": "2.4.0",
  "qemu_arch": "x86_64",
  "qemu_nic": ""
}
```
